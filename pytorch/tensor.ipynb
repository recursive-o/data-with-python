{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-13T12:28:00.259583Z",
     "start_time": "2025-01-13T12:27:58.838012Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 0.],\n",
      "        [1., 1., 1., 0.],\n",
      "        [1., 1., 1., 0.],\n",
      "        [1., 1., 1., 0.]])\n"
     ]
    }
   ],
   "source": [
    "tensor=torch.ones(4,4)\n",
    "tensor[...,-1]=0\n",
    "print(tensor)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-09T14:15:32.986634Z",
     "start_time": "2025-01-09T14:15:32.972728Z"
    }
   },
   "id": "3e809fe3d8ceb014"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "t1 = torch.ones(2, 2)\n",
    "t2 = torch.zeros(2, 2)\n",
    "\n",
    "# torch.cat: 주어진 텐서들을 주어진 차원에 맞춰 합쳐주는 함수\n",
    "\n",
    "t3 = torch.cat([t1, t2], dim=0)\n",
    "t4 = torch.cat([t1, t2], dim=1)\n",
    "\n",
    "print(t3)\n",
    "\n",
    "print(t3.shape)\n",
    "\n",
    "print(t4)\n",
    "\n",
    "print(t4.shape)\n",
    "\n",
    "# torch.stack: 주어진 텐서들을 새로운 차원으로 합쳐주는 함수, cat과 다르게 차원이 하나 더 추가된다\n",
    "# https://pytorch.org/docs/stable/generated/torch.stack.html\n",
    "t3 = torch.stack([t1, t2], dim=0)\n",
    "t4 = torch.stack([t1, t2], dim=1)\n",
    "\n",
    "print(t3)\n",
    "\n",
    "print(t3.shape)\n",
    "\n",
    "print(t4)\n",
    "\n",
    "print(t4.shape)\n",
    "\n",
    "# https://velog.io/@nochesita/PyTorch-torch.cat%EA%B3%BC-torch.stack%EC%9D%98-%EC%B0%A8%EC%9D%B4"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8a43bfc6e45a273"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y1 tensor([[3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.]])\n",
      "y2 tensor([[3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.]])\n",
      "y3 tensor([[0.2922, 0.0380, 0.2018, 0.6523],\n",
      "        [0.5348, 0.7503, 0.2164, 0.3012],\n",
      "        [0.2245, 0.7571, 0.5566, 0.2830],\n",
      "        [0.7791, 0.3784, 0.5574, 0.5718]])\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor([[3., 3., 3., 3.],\n        [3., 3., 3., 3.],\n        [3., 3., 3., 3.],\n        [3., 3., 3., 3.]])"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. torch.rand() : 0과 1 사이의 숫자를 균등하게 생성\n",
    "# 2. torch.rand_like() : 사이즈를 튜플로 입력하지 않고 기존의 텐서로 정의\n",
    "# https://bigdatadiary0819.tistory.com/60\n",
    "\n",
    "y1 = tensor @ tensor.T\n",
    "print('y1',y1)\n",
    "y2 = tensor.matmul(tensor.T)\n",
    "print('y2',y2)\n",
    "y3 = torch.rand_like(y1)\n",
    "print('y3',y3)\n",
    "torch.matmul(tensor, tensor.T, out=y3)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-09T14:33:38.945394Z",
     "start_time": "2025-01-09T14:33:38.929791Z"
    }
   },
   "id": "cd5eb9097499c7b0"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 0.],\n",
      "        [1., 1., 1., 0.],\n",
      "        [1., 1., 1., 0.],\n",
      "        [1., 1., 1., 0.]])\n",
      "tensor([[1., 1., 1., 0.],\n",
      "        [1., 1., 1., 0.],\n",
      "        [1., 1., 1., 0.],\n",
      "        [1., 1., 1., 0.]])\n",
      "tensor([[9.6822e-01, 4.0161e-02, 2.7655e-01, 1.6870e-01],\n",
      "        [3.5494e-01, 9.9783e-01, 1.3596e-01, 3.4666e-04],\n",
      "        [1.0692e-01, 1.3396e-01, 3.5912e-01, 9.3706e-01],\n",
      "        [2.2386e-01, 8.1597e-01, 2.6958e-01, 7.9137e-01]])\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor([[1., 1., 1., 0.],\n        [1., 1., 1., 0.],\n        [1., 1., 1., 0.],\n        [1., 1., 1., 0.]])"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z1 = tensor * tensor\n",
    "print(z1)\n",
    "z2 = tensor.mul(tensor)\n",
    "print(z2)\n",
    "z3 = torch.rand_like(tensor)\n",
    "print(z3)\n",
    "torch.mul(tensor, tensor, out=z3)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-09T14:36:27.609797Z",
     "start_time": "2025-01-09T14:36:27.604034Z"
    }
   },
   "id": "bb43850f7dde73b6"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 46.19044270604725\n",
      "199 35.128680743599425\n",
      "299 27.34709990638791\n",
      "399 21.870756998231933\n",
      "499 18.015452469352255\n",
      "599 15.300489638041116\n",
      "699 13.38800261622937\n",
      "799 12.040420806105914\n",
      "899 11.090632538125684\n",
      "999 10.421045856679438\n",
      "1099 9.948886259067178\n",
      "1199 9.615868927505996\n",
      "1299 9.380940726049825\n",
      "1399 9.215177427419775\n",
      "1499 9.098194788617624\n",
      "1599 9.015623430146661\n",
      "1699 8.957331575632228\n",
      "1799 8.916173748341446\n",
      "1899 8.88710950126958\n",
      "1999 8.866582573395371\n",
      "Result: y = 0.007355542753702494 + 0.8577729321576373 x + -0.0012689535217734196 x^2 + -0.0934771947252661 x^3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 무작위로 입력과 출력 데이터를 생성합니다\n",
    "x = np.linspace(-math.pi, math.pi, 2000)\n",
    "y = np.sin(x)\n",
    "\n",
    "# 무작위로 가중치를 초기화합니다\n",
    "a = np.random.randn()\n",
    "b = np.random.randn()\n",
    "c = np.random.randn()\n",
    "d = np.random.randn()\n",
    "\n",
    "learning_rate = 1e-6\n",
    "for t in range(2000):\n",
    "  # 순전파 단계: 예측값 y를 계산합니다\n",
    "  # y = a + b x + c x^2 + d x^3\n",
    "  y_pred = a + b * x + c * x ** 2 + d * x ** 3\n",
    "\n",
    "  # 손실(loss)을 계산하고 출력합니다\n",
    "  loss = np.square(y_pred - y).sum()\n",
    "  if t % 100 == 99:\n",
    "    print(t, loss)\n",
    "\n",
    "  # 손실에 따른 a, b, c, d의 변화도(gradient)를 계산하고 역전파합니다.\n",
    "  grad_y_pred = 2.0 * (y_pred - y)\n",
    "  grad_a = grad_y_pred.sum()\n",
    "  grad_b = (grad_y_pred * x).sum()\n",
    "  grad_c = (grad_y_pred * x ** 2).sum()\n",
    "  grad_d = (grad_y_pred * x ** 3).sum()\n",
    "\n",
    "  # 가중치를 갱신합니다.\n",
    "  a -= learning_rate * grad_a\n",
    "  b -= learning_rate * grad_b\n",
    "  c -= learning_rate * grad_c\n",
    "  d -= learning_rate * grad_d\n",
    "\n",
    "print(f'Result: y = {a} + {b} x + {c} x^2 + {d} x^3')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-13T12:39:40.531523Z",
     "start_time": "2025-01-13T12:39:40.359698Z"
    }
   },
   "id": "2147a2441ee5ab"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-3.1416, -3.1384, -3.1353,  ...,  3.1353,  3.1384,  3.1416])\n"
     ]
    },
    {
     "data": {
      "text/plain": "torch.Size([2000, 1])"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(x)\n",
    "x.unsqueeze(-1).shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-13T13:15:04.722498Z",
     "start_time": "2025-01-13T13:15:04.711157Z"
    }
   },
   "id": "d799dc93a834039b"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 345.5351867675781\n",
      "199 246.50732421875\n",
      "299 176.63162231445312\n",
      "399 127.31527709960938\n",
      "499 92.50318145751953\n",
      "599 67.92574310302734\n",
      "699 50.57140350341797\n",
      "799 38.31568145751953\n",
      "899 29.659460067749023\n",
      "999 23.54486083984375\n",
      "1099 19.225114822387695\n",
      "1199 16.173017501831055\n",
      "1299 14.01637077331543\n",
      "1399 12.492307662963867\n",
      "1499 11.415184020996094\n",
      "1599 10.653870582580566\n",
      "1699 10.11573600769043\n",
      "1799 9.735321998596191\n",
      "1899 9.466384887695312\n",
      "1999 9.276246070861816\n",
      "Result: y = 0.022558296099305153 + 0.8545917868614197 x + -0.003891679225489497 x^2 + -0.09302470088005066 x^3\n"
     ]
    }
   ],
   "source": [
    "dtype = torch.float\n",
    "device = torch.device(\"cpu\")\n",
    "# device = torch.device(\"cuda:0\") # GPU에서 실행하려면 이 주석을 제거하세요\n",
    "\n",
    "# 무작위로 입력과 출력 데이터를 생성합니다\n",
    "x = torch.linspace(-math.pi, math.pi, 2000, device=device, dtype=dtype)\n",
    "y = torch.sin(x)\n",
    "\n",
    "# 무작위로 가중치를 초기화합니다\n",
    "a = torch.randn((), device=device, dtype=dtype)\n",
    "b = torch.randn((), device=device, dtype=dtype)\n",
    "c = torch.randn((), device=device, dtype=dtype)\n",
    "d = torch.randn((), device=device, dtype=dtype)\n",
    "\n",
    "learning_rate = 1e-6\n",
    "for t in range(2000):\n",
    "  # 순전파 단계: 예측값 y를 계산합니다\n",
    "  y_pred = a + b * x + c * x ** 2 + d * x ** 3\n",
    "\n",
    "  # 손실(loss)을 계산하고 출력합니다\n",
    "  loss = (y_pred - y).pow(2).sum().item()\n",
    "  if t % 100 == 99:\n",
    "    print(t, loss)\n",
    "\n",
    "  # 손실에 따른 a, b, c, d의 변화도(gradient)를 계산하고 역전파합니다.\n",
    "  grad_y_pred = 2.0 * (y_pred - y)\n",
    "  grad_a = grad_y_pred.sum()\n",
    "  grad_b = (grad_y_pred * x).sum()\n",
    "  grad_c = (grad_y_pred * x ** 2).sum()\n",
    "  grad_d = (grad_y_pred * x ** 3).sum()\n",
    "\n",
    "  # 가중치를 갱신합니다.\n",
    "  a -= learning_rate * grad_a\n",
    "  b -= learning_rate * grad_b\n",
    "  c -= learning_rate * grad_c\n",
    "  d -= learning_rate * grad_d\n",
    "\n",
    "\n",
    "print(f'Result: y = {a.item()} + {b.item()} x + {c.item()} x^2 + {d.item()} x^3')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-13T12:42:27.271565Z",
     "start_time": "2025-01-13T12:42:27.153267Z"
    }
   },
   "id": "fcc215eb47a83240"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss.shape torch.Size([])\n",
      "99 1407.66650390625\n",
      "199 966.8894653320312\n",
      "299 665.7542114257812\n",
      "399 459.78387451171875\n",
      "499 318.74285888671875\n",
      "599 222.0520782470703\n",
      "699 155.68994140625\n",
      "799 110.0914306640625\n",
      "899 78.72491455078125\n",
      "999 57.12431335449219\n",
      "1099 42.23255920410156\n",
      "1199 31.9549617767334\n",
      "1299 24.854345321655273\n",
      "1399 19.943470001220703\n",
      "1499 16.54364776611328\n",
      "1599 14.187583923339844\n",
      "1699 12.55324935913086\n",
      "1799 11.418477058410645\n",
      "1899 10.629875183105469\n",
      "1999 10.081345558166504\n",
      "Result: y = 0.033458977937698364 + 0.8409170508384705 x + -0.005772230215370655 x^2 + -0.09107958525419235 x^3\n"
     ]
    }
   ],
   "source": [
    "dtype=torch.float\n",
    "device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch.set_default_device(device)\n",
    "\n",
    "x=torch.linspace(-math.pi, math.pi,2000,dtype=dtype)\n",
    "y=torch.sin(x)\n",
    "\n",
    "a=torch.randn((), dtype=dtype, requires_grad=True)\n",
    "b=torch.randn((), dtype=dtype, requires_grad=True)\n",
    "c=torch.randn((), dtype=dtype, requires_grad=True)\n",
    "d=torch.randn((), dtype=dtype, requires_grad=True)\n",
    "\n",
    "learning_rate=1e-6\n",
    "for t in range(2000):\n",
    "  y_pred=a+b*x+c*x**2+d*x**3\n",
    "  loss=(y_pred-y).pow(2).sum()\n",
    "  if t == 0 :  print('loss.shape',loss.shape)\n",
    "  if t%100 == 99:\n",
    "    print(t, loss.item())\n",
    "    \n",
    "  loss.backward()\n",
    "  \n",
    "  with torch.no_grad():\n",
    "    a -= learning_rate*a.grad\n",
    "    b -= learning_rate*b.grad\n",
    "    c -= learning_rate*c.grad\n",
    "    d -= learning_rate*d.grad\n",
    "    \n",
    "    a.grad=None\n",
    "    b.grad=None\n",
    "    c.grad=None\n",
    "    d.grad=None\n",
    "\n",
    "print(f'Result: y = {a.item()} + {b.item()} x + {c.item()} x^2 + {d.item()} x^3')    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-13T12:52:30.678145Z",
     "start_time": "2025-01-13T12:52:30.359676Z"
    }
   },
   "id": "8a3a6df1b539a2e4"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(True)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.full((),5)==torch.tensor(5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-13T13:03:17.004721Z",
     "start_time": "2025-01-13T13:03:16.997180Z"
    }
   },
   "id": "a60aa5382ffef18c"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 1279.6165771484375\n",
      "199 855.3080444335938\n",
      "299 572.9288940429688\n",
      "399 384.9282531738281\n",
      "499 259.7086181640625\n",
      "599 176.26751708984375\n",
      "699 120.63961029052734\n",
      "799 83.5351333618164\n",
      "899 58.773231506347656\n",
      "999 42.23881149291992\n",
      "1099 31.192058563232422\n",
      "1199 23.806941986083984\n",
      "1299 18.866796493530273\n",
      "1399 15.559850692749023\n",
      "1499 13.344681739807129\n",
      "1599 11.859766006469727\n",
      "1699 10.86358642578125\n",
      "1799 10.194780349731445\n",
      "1899 9.745405197143555\n",
      "1999 9.44318962097168\n",
      "Result: y = 0.014454414136707783 + 0.83636075258255 x + -0.002493626903742552 x^2 + -0.09043149650096893 x^3\n"
     ]
    }
   ],
   "source": [
    "# 입력값과 출력값을 갖는 텐서들을 생성합니다.\n",
    "x = torch.linspace(-math.pi, math.pi, 2000)\n",
    "y = torch.sin(x)\n",
    "\n",
    "# 이 예제에서, 출력 y는 (x, x^2, x^3)의 선형 함수이므로, 선형 계층 신경망으로 간주할 수 있습니다.\n",
    "# (x, x^2, x^3)를 위한 텐서를 준비합니다.\n",
    "p = torch.tensor([1, 2, 3])\n",
    "xx = x.unsqueeze(-1).pow(p)\n",
    "\n",
    "# 위 코드에서, x.unsqueeze(-1)은 (2000, 1)의 shape을, p는 (3,)의 shape을 가지므로,\n",
    "# 이 경우 브로드캐스트(broadcast)가 적용되어 (2000, 3)의 shape을 갖는 텐서를 얻습니다. \n",
    "# Broadcastig은 두 텐서가 서로 다른 크기일 때, 자동으로 차원을 맞춰 연산을 수행할 수 있게 해주는 기능\n",
    "\n",
    "# nn 패키지를 사용하여 모델을 순차적 계층(sequence of layers)으로 정의합니다.\n",
    "# nn.Sequential은 다른 Module을 포함하는 Module로, 포함되는 Module들을 순차적으로 적용하여 \n",
    "# 출력을 생성합니다. 각각의 Linear Module은 선형 함수(linear function)를 사용하여 입력으로부터\n",
    "# 출력을 계산하고, 내부 Tensor에 가중치와 편향을 저장합니다.\n",
    "# Flatten 계층은 선형 계층의 출력을 `y` 의 shape과 맞도록(match) 1D 텐서로 폅니다(flatten).\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(3, 1),\n",
    "    torch.nn.Flatten(0, 1)\n",
    ")\n",
    "\n",
    "# 또한 nn 패키지에는 주로 사용되는 손실 함수(loss function)들에 대한 정의도 포함되어 있습니다;\n",
    "# 여기에서는 평균 제곱 오차(MSE; Mean Squared Error)를 손실 함수로 사용하겠습니다.\n",
    "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "\n",
    "learning_rate = 1e-6\n",
    "for t in range(2000):\n",
    "\n",
    "  # 순전파 단계: x를 모델에 전달하여 예측값 y를 계산합니다. Module 객체는 __call__ 연산자를 \n",
    "  # 덮어써서(override) 함수처럼 호출할 수 있도록 합니다. 이렇게 함으로써 입력 데이터의 텐서를 Module에 전달하여\n",
    "  # 출력 데이터의 텐서를 생성합니다.\n",
    "  y_pred = model(xx)\n",
    "\n",
    "  # 손실을 계산하고 출력합니다. 예측한 y와 정답인 y를 갖는 텐서들을 전달하고,\n",
    "  # 손실 함수는 손실(loss)을 갖는 텐서를 반환합니다.\n",
    "  loss = loss_fn(y_pred, y)\n",
    "  if t % 100 == 99:\n",
    "    print(t, loss.item())\n",
    "\n",
    "  # 역전파 단계를 실행하기 전에 변화도(gradient)를 0으로 만듭니다.\n",
    "  model.zero_grad()\n",
    "\n",
    "  # 역전파 단계: 모델의 학습 가능한 모든 매개변수에 대해 손실의 변화도를 계산합니다.\n",
    "  # 내부적으로 각 Module의 매개변수는 requires_grad=True일 때 텐서에 저장되므로,\n",
    "  # 아래 호출은 모델의 모든 학습 가능한 매개변수의 변화도를 계산하게 됩니다.\n",
    "  loss.backward()\n",
    "\n",
    "  # 경사하강법을 사용하여 가중치를 갱신합니다.\n",
    "  # 각 매개변수는 텐서이므로, 이전에 했던 것처럼 변화도에 접근할 수 있습니다.\n",
    "  with torch.no_grad():\n",
    "    for param in model.parameters():\n",
    "      param -= learning_rate * param.grad\n",
    "\n",
    "# list의 첫번째 항목에 접근하는 것처럼 `model` 의 첫번째 계층(layer)에 접근할 수 있습니다.\n",
    "linear_layer = model[0]\n",
    "\n",
    "# 선형 계층에서, 매개변수는 `weights` 와 `bias` 로 저장됩니다.\n",
    "print(f'Result: y = {linear_layer.bias.item()} + {linear_layer.weight[:, 0].item()} x + {linear_layer.weight[:, 1].item()} x^2 + {linear_layer.weight[:, 2].item()} x^3')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-13T13:19:48.722595Z",
     "start_time": "2025-01-13T13:19:48.483231Z"
    }
   },
   "id": "976d8ac74c9966a2"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "0.83636075258255"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(xx)\n",
    "linear_layer.weight[0,0].item()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-13T13:24:03.742404Z",
     "start_time": "2025-01-13T13:24:03.733925Z"
    }
   },
   "id": "ec6c6eddd121ef85"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "7b27048bb2bc3616"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
